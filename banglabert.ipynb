{"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"widgets":{"application/vnd.jupyter.widget-state+json":{"429121514b9942019b8ba5400f9bdead":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f3d7d69d67849e4bb00dcd04dd00855","IPY_MODEL_8b09a2f4d9c44838bda5851a668564e4","IPY_MODEL_ac041b1c723a40a496c234bbe5f1352b"],"layout":"IPY_MODEL_cda44b48f7cc4d30b0364036037dad19"}},"6f3d7d69d67849e4bb00dcd04dd00855":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f18f3aa50be48fc9ba2da555b647f50","placeholder":"​","style":"IPY_MODEL_8cf5996ea6134134845d11a74c5f297c","value":"config.json: 100%"}},"8b09a2f4d9c44838bda5851a668564e4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9e3e543969841f580e41cfc2d31fe1c","max":586,"min":0,"orientation":"horizontal","style":"IPY_MODEL_21e4e82578a64777b325f104069b0074","value":586}},"ac041b1c723a40a496c234bbe5f1352b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e1bd2693765d49fd80e22a205c2e85df","placeholder":"​","style":"IPY_MODEL_cc7451fa0ac54276af32a1851249217b","value":" 586/586 [00:00&lt;00:00, 5.44kB/s]"}},"cda44b48f7cc4d30b0364036037dad19":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7f18f3aa50be48fc9ba2da555b647f50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cf5996ea6134134845d11a74c5f297c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e9e3e543969841f580e41cfc2d31fe1c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"21e4e82578a64777b325f104069b0074":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e1bd2693765d49fd80e22a205c2e85df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc7451fa0ac54276af32a1851249217b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c6e49b093e4344fc9337ae481ea1d6c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_863434a910dc403dbc095fc810450f1a","IPY_MODEL_3b7bd3bfc8fe4210ba970e33e9a71ae3","IPY_MODEL_d8e7a47b9c0f4a249b80465d96dba66b"],"layout":"IPY_MODEL_252f09e8a1a54c2da3ba3c2f9f0a4dec"}},"863434a910dc403dbc095fc810450f1a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a6993c895ba642cca32a39cf0caba81e","placeholder":"​","style":"IPY_MODEL_30eb51709f0f4c6e8b5fbbcc545bdb56","value":"pytorch_model.bin: 100%"}},"3b7bd3bfc8fe4210ba970e33e9a71ae3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_86e99394e10f44e8a3d9d00ea2202fae","max":442560329,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5a0b94655864e2c979921e318a293d5","value":442560329}},"d8e7a47b9c0f4a249b80465d96dba66b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5beefa7832634f58b494904bc7acfeb9","placeholder":"​","style":"IPY_MODEL_f5caf46100ca4f7f829b4dbd3d7aa822","value":" 443M/443M [00:07&lt;00:00, 87.3MB/s]"}},"252f09e8a1a54c2da3ba3c2f9f0a4dec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6993c895ba642cca32a39cf0caba81e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30eb51709f0f4c6e8b5fbbcc545bdb56":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86e99394e10f44e8a3d9d00ea2202fae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5a0b94655864e2c979921e318a293d5":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5beefa7832634f58b494904bc7acfeb9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5caf46100ca4f7f829b4dbd3d7aa822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccce99dc7ab7412684ce63f6bbed924c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_85304fec5d624c0dad0a16a09e87c0c7","IPY_MODEL_3a09fc73bf0f4733a0ec6fdc271b1775","IPY_MODEL_16ac9ea7630e495c94e3c27adb9716e8"],"layout":"IPY_MODEL_4f40f1f218884ca9a650f0dbb615cafb"}},"85304fec5d624c0dad0a16a09e87c0c7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_340f1e6c4363425ba69808ecc644f134","placeholder":"​","style":"IPY_MODEL_48a91d5f880346f0b68301deb30124b8","value":"tokenizer_config.json: 100%"}},"3a09fc73bf0f4733a0ec6fdc271b1775":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_9cc7f16384f84306b9908c49245d2665","max":119,"min":0,"orientation":"horizontal","style":"IPY_MODEL_417788178c4949958e7133d7f533056d","value":119}},"16ac9ea7630e495c94e3c27adb9716e8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e99e1ec5be58419da1b037a14a62fb29","placeholder":"​","style":"IPY_MODEL_a551d6f1b848455b8edaa9f4b35846c9","value":" 119/119 [00:00&lt;00:00, 1.19kB/s]"}},"4f40f1f218884ca9a650f0dbb615cafb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"340f1e6c4363425ba69808ecc644f134":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48a91d5f880346f0b68301deb30124b8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9cc7f16384f84306b9908c49245d2665":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"417788178c4949958e7133d7f533056d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e99e1ec5be58419da1b037a14a62fb29":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a551d6f1b848455b8edaa9f4b35846c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8a77649ad3424038ad3d12a883bba12b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_266b2984d4574d88924eae338aefa089","IPY_MODEL_73754cdc8b0b415cbffbb874bd440270","IPY_MODEL_bff3912ecb9b4166960e59079264f202"],"layout":"IPY_MODEL_fcce9e52d06541dabacaf393b17690f3"}},"266b2984d4574d88924eae338aefa089":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5211b53d5994dfab9ea8d088bad6735","placeholder":"​","style":"IPY_MODEL_d65d78aa1b0747448237447dada8518c","value":"vocab.txt: 100%"}},"73754cdc8b0b415cbffbb874bd440270":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_73951398bb8b439e9e1c5a7a56473ff4","max":528316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ef991c408e554d79a934a50a03025b5a","value":528316}},"bff3912ecb9b4166960e59079264f202":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74c35621a4bf42e7bb4220cfd7d2946a","placeholder":"​","style":"IPY_MODEL_81a41b5eebf543f4b4fd14a12c17725f","value":" 528k/528k [00:00&lt;00:00, 4.36MB/s]"}},"fcce9e52d06541dabacaf393b17690f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5211b53d5994dfab9ea8d088bad6735":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d65d78aa1b0747448237447dada8518c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73951398bb8b439e9e1c5a7a56473ff4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef991c408e554d79a934a50a03025b5a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"74c35621a4bf42e7bb4220cfd7d2946a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"81a41b5eebf543f4b4fd14a12c17725f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73e66eb006da45ff87b3f81b8805d1dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_daa6654744d949488dca3856f4c83068","IPY_MODEL_38416977d0f347c487bd18ace0d73efd","IPY_MODEL_9b7ec0e4ce1347ecb7ec5cf564f2c4f8"],"layout":"IPY_MODEL_03cb975ca36542629278589ade3590d8"}},"daa6654744d949488dca3856f4c83068":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3aed2d108a8d4470bbf36168cdd653ab","placeholder":"​","style":"IPY_MODEL_d492fa6d35284ac6878af2e7b16fce5a","value":"special_tokens_map.json: 100%"}},"38416977d0f347c487bd18ace0d73efd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_50eecab4b29a4df1ae116a6f97b77af2","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e05285feacab4eb1b858f37783754dff","value":112}},"9b7ec0e4ce1347ecb7ec5cf564f2c4f8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9e30a86bdf784aa49afeecadc60b008d","placeholder":"​","style":"IPY_MODEL_9337ccacdd2f415e95294df1f742ebd6","value":" 112/112 [00:00&lt;00:00, 1.16kB/s]"}},"03cb975ca36542629278589ade3590d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3aed2d108a8d4470bbf36168cdd653ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d492fa6d35284ac6878af2e7b16fce5a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50eecab4b29a4df1ae116a6f97b77af2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e05285feacab4eb1b858f37783754dff":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9e30a86bdf784aa49afeecadc60b008d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9337ccacdd2f415e95294df1f742ebd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e2617f931c444f58b0ccb9649527680":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc4d530f0b3d438a9ad64955a10a7011","IPY_MODEL_ad38e2b0d53d41a8a42c6aa5ce03ae70","IPY_MODEL_47dfa97370e74a1bb68847fe380f4b47"],"layout":"IPY_MODEL_d8026ac7d54c4d078b0963f296f3198b"}},"bc4d530f0b3d438a9ad64955a10a7011":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3cd0becb06da485b942208514af75436","placeholder":"​","style":"IPY_MODEL_be22b4adc4d145b882eecd0cb35ba531","value":"  0%"}},"ad38e2b0d53d41a8a42c6aa5ce03ae70":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc6657b5da8b45e3b183fb209f2544c7","max":5389,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72281ee75f3c444f9b102b3eabaa3050","value":6}},"47dfa97370e74a1bb68847fe380f4b47":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9aa909bfdcd142edb4095173209d6656","placeholder":"​","style":"IPY_MODEL_be3923c9d6fc4177b75465a301b897d1","value":" 6/5389 [06:09&lt;88:42:11, 59.32s/it]"}},"d8026ac7d54c4d078b0963f296f3198b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd0becb06da485b942208514af75436":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be22b4adc4d145b882eecd0cb35ba531":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dc6657b5da8b45e3b183fb209f2544c7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72281ee75f3c444f9b102b3eabaa3050":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9aa909bfdcd142edb4095173209d6656":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be3923c9d6fc4177b75465a301b897d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7650786,"sourceType":"datasetVersion","datasetId":4460127}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1>loading train, validation and test data<h1>","metadata":{"id":"9dBC0DJLIEKX"}},{"cell_type":"code","source":"!pip install --quiet transformers","metadata":{"id":"F3xXUMDVfRI7","executionInfo":{"status":"ok","timestamp":1708276361086,"user_tz":-360,"elapsed":12337,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T17:44:59.449273Z","iopub.execute_input":"2024-02-18T17:44:59.449920Z","iopub.status.idle":"2024-02-18T17:45:17.117720Z","shell.execute_reply.started":"2024-02-18T17:44:59.449877Z","shell.execute_reply":"2024-02-18T17:45:17.115706Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import time\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom transformers import BertModel, BertTokenizer, BertForSequenceClassification, AutoModelForMaskedLM, AutoTokenizer","metadata":{"id":"KJs3tsZEdtJP","executionInfo":{"status":"ok","timestamp":1708276397391,"user_tz":-360,"elapsed":10477,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T17:45:22.895250Z","iopub.execute_input":"2024-02-18T17:45:22.895762Z","iopub.status.idle":"2024-02-18T17:45:32.800288Z","shell.execute_reply.started":"2024-02-18T17:45:22.895721Z","shell.execute_reply":"2024-02-18T17:45:32.798946Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"###Hyperparameter for the new model\n#defining some hyperparameters\nmax_number_input_tokens=512\nbatch_size_training = 8\nfirst_dropout_rate = 0.0\nhidden_output = 768\nbert_model_name = \"csebuetnlp/banglabert\"\nadam_opt_lr = 3e-5\nscheduler_step = 1\nscheduler_gamma = 0.98\nepochs = 8\nclasses = 4\nmodel_layer = ''\nname_change=''\nheadlineContentSeparator = ' \\\\\\\\ '\n\n#other options\nisSaveModel = False","metadata":{"id":"7Q8iG3vluRLA","executionInfo":{"status":"ok","timestamp":1708276406843,"user_tz":-360,"elapsed":444,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T17:45:40.076102Z","iopub.execute_input":"2024-02-18T17:45:40.076514Z","iopub.status.idle":"2024-02-18T17:45:40.082807Z","shell.execute_reply.started":"2024-02-18T17:45:40.076482Z","shell.execute_reply":"2024-02-18T17:45:40.081548Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from google.colab import drive\ndrive.mount('/content/drive')","metadata":{"id":"y_mgBaV-HbsI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708276476218,"user_tz":-360,"elapsed":55624,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"outputId":"f8f7677f-dc78-400b-eee3-0f5a82d34182"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":"Mounted at /content/drive\n"}]},{"cell_type":"code","source":"DirPath = ('/kaggle/input/mis-dis-satire/')\nTestPath = DirPath+'test_data.csv'\nValPath = DirPath+'val_data.csv'\nTrainPath = DirPath+'train_data.csv'\nModelPath = DirPath+'Models/'+'FNBaseline_buetbertrHritThesis.pth'","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3313,"status":"ok","timestamp":1708276691572,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"},"user_tz":-360},"id":"rXg4692CZ5cb","outputId":"e1e69efa-3b4e-49a9-abea-b8655555219b","execution":{"iopub.status.busy":"2024-02-18T17:46:15.033323Z","iopub.execute_input":"2024-02-18T17:46:15.033729Z","iopub.status.idle":"2024-02-18T17:46:15.039930Z","shell.execute_reply.started":"2024-02-18T17:46:15.033698Z","shell.execute_reply":"2024-02-18T17:46:15.038782Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#df loading\ndf_train = pd.read_csv(TrainPath) # [['sentence','hate speech']]\ndf_val = pd.read_csv(ValPath)#[['sentence','hate speech']]\ndf_test = pd.read_csv(TestPath)#[['sentence','hate speech']]\n\n#concatenating all the data\n# df_train = pd.concat([df_train, df_val, df_test], ignore_index=True)\n\nprint(df_train.shape)\nprint(df_val.shape)\nprint(df_test.shape)\ndisplay(df_train)\nprint(df_train.describe())\nprint(df_train['Label'].value_counts())\nprint(df_val['Label'].value_counts())\nprint(df_test['Label'].value_counts())","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":892},"executionInfo":{"elapsed":16700,"status":"ok","timestamp":1708276710152,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"},"user_tz":-360},"id":"Z-k2B2ThB8SY","outputId":"56d5f2b4-3070-4799-a945-5f44794092a4","execution":{"iopub.status.busy":"2024-02-18T17:46:19.276260Z","iopub.execute_input":"2024-02-18T17:46:19.276702Z","iopub.status.idle":"2024-02-18T17:46:26.665246Z","shell.execute_reply.started":"2024-02-18T17:46:19.276668Z","shell.execute_reply":"2024-02-18T17:46:26.663977Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"(43105, 3)\n(9237, 3)\n(9238, 3)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                                Headline  \\\n0                          বরিশাল কারাগারে হাজতির মৃত্যু   \n1        সারা দেশে গণহারে গ্রেপ্তারের ঘটনা উদ্বেগের কারণ   \n2            মসজিদে নামাজরত অবস্থায় শাবি শিক্ষকের মৃত্যু   \n3        বাগেরহাটে আওয়ামী লীগের দু’গ্রুপে সংঘর্ষে নিহত ২   \n4                     'ছবির ক্যাপশন অতিরঞ্জিত করা হয়েছে'   \n...                                                  ...   \n43100  খালেদার স্বাস্থ্য পরীক্ষার জন্য বিএসএমএমইউ গেল...   \n43101                                 পিভিসি পাইপে ইয়াবা   \n43102  ইয়াসের ক্ষতিপূরণ চেয়ে ভুরি ভুরি ‘ভুয়ো আবেদনপত্...   \n43103  উত্তর কোরিয়াকে জ্বালানি দেয়ার মার্কিন অভিযোগ প...   \n43104  রিয়াল মাদ্রিদের আশা ছাড়েননি হ্যাজার্ড ০৯ অক্টো...   \n\n                                                 Content  Label  \n0      বরিশাল কেন্দ্রীয় কারাগারে খলিলুর রহমান নান্টু ...    3.0  \n1      সারা দেশে দলীয় নেতা–কর্মীদের গ্রেপ্তার প্রসঙ্গ...    3.0  \n2      শাহজালাল বিজ্ঞান ও প্রযুক্তি বিশ্ববিদ্যালয়ের ম...    3.0  \n3      বাগেরহাটের মোরেলগঞ্জে আওয়ামী লীগের দুই গ্রুপের...    3.0  \n4      'এটি কনভোকেশনের সেরা ও শ্রেষ্ঠ ছবি। নিশ্চিত সে...    3.0  \n...                                                  ...    ...  \n43100  বেগম জিয়ার স্বাস্থ্য পরীক্ষার জন্য দ্বিতীয় দিন...    3.0  \n43101  সিরাজগঞ্জে কুরিয়ার সার্ভিসের মাধ্যমে আসা পিভিস...    3.0  \n43102  এ যেন সেই আমফানেরই পুনরাবৃত্তি। আমফানের পর ক্ষ...    2.0  \n43103  নিষেধাজ্ঞা লঙ্ঘন করে উত্তর কোরিয়াকে জ্বালানি ত...    3.0  \n43104  স্প্যানিশ জায়ান্ট রিয়াল মাদ্রিদের হয়ে খেলার স্...    3.0  \n\n[43105 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Headline</th>\n      <th>Content</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>বরিশাল কারাগারে হাজতির মৃত্যু</td>\n      <td>বরিশাল কেন্দ্রীয় কারাগারে খলিলুর রহমান নান্টু ...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>সারা দেশে গণহারে গ্রেপ্তারের ঘটনা উদ্বেগের কারণ</td>\n      <td>সারা দেশে দলীয় নেতা–কর্মীদের গ্রেপ্তার প্রসঙ্গ...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>মসজিদে নামাজরত অবস্থায় শাবি শিক্ষকের মৃত্যু</td>\n      <td>শাহজালাল বিজ্ঞান ও প্রযুক্তি বিশ্ববিদ্যালয়ের ম...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>বাগেরহাটে আওয়ামী লীগের দু’গ্রুপে সংঘর্ষে নিহত ২</td>\n      <td>বাগেরহাটের মোরেলগঞ্জে আওয়ামী লীগের দুই গ্রুপের...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>'ছবির ক্যাপশন অতিরঞ্জিত করা হয়েছে'</td>\n      <td>'এটি কনভোকেশনের সেরা ও শ্রেষ্ঠ ছবি। নিশ্চিত সে...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>43100</th>\n      <td>খালেদার স্বাস্থ্য পরীক্ষার জন্য বিএসএমএমইউ গেল...</td>\n      <td>বেগম জিয়ার স্বাস্থ্য পরীক্ষার জন্য দ্বিতীয় দিন...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>43101</th>\n      <td>পিভিসি পাইপে ইয়াবা</td>\n      <td>সিরাজগঞ্জে কুরিয়ার সার্ভিসের মাধ্যমে আসা পিভিস...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>43102</th>\n      <td>ইয়াসের ক্ষতিপূরণ চেয়ে ভুরি ভুরি ‘ভুয়ো আবেদনপত্...</td>\n      <td>এ যেন সেই আমফানেরই পুনরাবৃত্তি। আমফানের পর ক্ষ...</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>43103</th>\n      <td>উত্তর কোরিয়াকে জ্বালানি দেয়ার মার্কিন অভিযোগ প...</td>\n      <td>নিষেধাজ্ঞা লঙ্ঘন করে উত্তর কোরিয়াকে জ্বালানি ত...</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>43104</th>\n      <td>রিয়াল মাদ্রিদের আশা ছাড়েননি হ্যাজার্ড ০৯ অক্টো...</td>\n      <td>স্প্যানিশ জায়ান্ট রিয়াল মাদ্রিদের হয়ে খেলার স্...</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>43105 rows × 3 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"              Label\ncount  43103.000000\nmean       2.663295\nstd        0.746240\nmin        0.000000\n25%        3.000000\n50%        3.000000\n75%        3.000000\nmax        3.000000\nLabel\n3.0    34092\n2.0     5195\n1.0     2130\n0.0     1686\nName: count, dtype: int64\nLabel\n3.0    7273\n2.0    1115\n1.0     489\n0.0     360\nName: count, dtype: int64\nLabel\n3.0    7313\n2.0    1112\n1.0     462\n0.0     351\nName: count, dtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"<h1>preparing training, validation and test data. Preparing model. Training model<h1>","metadata":{"id":"nhygxywpTztv"}},{"cell_type":"code","source":"class NewsDatasets(Dataset):\n    def __init__(self, data, max_length=max_number_input_tokens):\n        self.data = data\n\n        self.config = {\n            \"max_length\": max_length,\n            \"padding\": \"max_length\",\n            \"return_tensors\": \"pt\",\n            \"truncation\": True,\n            \"add_special_tokens\": True,\n            \"truncation_strategy\":\"longest_first\"\n        }\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        value = self.data.iloc[idx]\n        # print(value[\"Headline\"],value['Content']) #debugging dataloader\n        return value['Headline']+headlineContentSeparator+value['Content'] , value['Label']","metadata":{"id":"MtIzKtM_xqHt","executionInfo":{"status":"ok","timestamp":1708276717615,"user_tz":-360,"elapsed":348,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T17:46:33.921089Z","iopub.execute_input":"2024-02-18T17:46:33.921556Z","iopub.status.idle":"2024-02-18T17:46:33.932108Z","shell.execute_reply.started":"2024-02-18T17:46:33.921515Z","shell.execute_reply":"2024-02-18T17:46:33.930449Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"training_data = NewsDatasets(df_train)\ntrain_dataloader = DataLoader(training_data, batch_size=batch_size_training, shuffle=True)\n\nval_data = NewsDatasets(df_val)\nval_dataloader = DataLoader(val_data, batch_size=batch_size_training, shuffle=False)\n\ntest_data = NewsDatasets(df_test)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size_training, shuffle=False)","metadata":{"id":"aK9mkfgDxrVZ","executionInfo":{"status":"ok","timestamp":1708276737513,"user_tz":-360,"elapsed":476,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T17:46:38.315230Z","iopub.execute_input":"2024-02-18T17:46:38.315648Z","iopub.status.idle":"2024-02-18T17:46:38.323489Z","shell.execute_reply.started":"2024-02-18T17:46:38.315617Z","shell.execute_reply":"2024-02-18T17:46:38.322008Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class BERTBengali(nn.Module):\n    def __init__(self, bert):\n        super(BERTBengali, self).__init__()\n        #self.bert = BertForMaskedLM.from_pretrained(\"sagorsarker/bangla-bert-base\")\n        self.bert = bert\n        self.bert_drop = nn.Dropout(first_dropout_rate)\n        self.out = nn.Linear(hidden_output, classes)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output = self.bert(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids\n        )\n        bo = self.bert_drop(output[1])\n\n        output = self.out(bo)\n        return output","metadata":{"id":"sC7wjuyGAA5y","executionInfo":{"status":"ok","timestamp":1708276740451,"user_tz":-360,"elapsed":472,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T17:46:41.015134Z","iopub.execute_input":"2024-02-18T17:46:41.016244Z","iopub.status.idle":"2024-02-18T17:46:41.024257Z","shell.execute_reply.started":"2024-02-18T17:46:41.016204Z","shell.execute_reply":"2024-02-18T17:46:41.022822Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"bert = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\ntokenizer = AutoTokenizer.from_pretrained(bert_model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# bert = BertModel.from_pretrained(bert_model_name, output_hidden_states=True)\nmodel = BERTBengali(bert)\n# model2Forlastlayers = CustomBERTBengali(bert)\n\nmodel.to(device)\n# model2Forlastlayers.to(device)\n# model2Forlastlayers.load_state_dict(torch.load(DirPath+'Models by Sami/'+bert_model_name+\"_modeltest.pth\"))\n\n# model.l0 = model2Forlastlayers.l0\n# model.l2 = model2Forlastlayers.l1\n# model.bert = model2Forlastlayers.bert\n\n# model.load_state_dict(torch.load(DirPath+bert_model_name+\"_lasttwopoolerf_contest_val_from_HScollected_lastfrozen_acc1_sub.pth\"))\n\n# for params in model.bert.parameters():\n#   params.requires_grad = False\n# for params in model.bert.embeddings.parameters():\n#   params.requires_grad = True\n# for params in model.bert.encoder.parameters():\n#   params.requires_grad = False\n# # for params in model.l2.parameters():\n# #   params.requires_grad = True\n# # for params in model.l1.parameters():\n# #   params.requires_grad = True\n# for params in model.l0.parameters():\n#   params.requires_grad = True\n\nfor name, param in model.named_parameters():\n  if param.requires_grad:\n      print(f\"name: {name} is trainable\")\n  else:\n      print(f\"name: {name} is non-trainable\")","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["429121514b9942019b8ba5400f9bdead","6f3d7d69d67849e4bb00dcd04dd00855","8b09a2f4d9c44838bda5851a668564e4","ac041b1c723a40a496c234bbe5f1352b","cda44b48f7cc4d30b0364036037dad19","7f18f3aa50be48fc9ba2da555b647f50","8cf5996ea6134134845d11a74c5f297c","e9e3e543969841f580e41cfc2d31fe1c","21e4e82578a64777b325f104069b0074","e1bd2693765d49fd80e22a205c2e85df","cc7451fa0ac54276af32a1851249217b","c6e49b093e4344fc9337ae481ea1d6c2","863434a910dc403dbc095fc810450f1a","3b7bd3bfc8fe4210ba970e33e9a71ae3","d8e7a47b9c0f4a249b80465d96dba66b","252f09e8a1a54c2da3ba3c2f9f0a4dec","a6993c895ba642cca32a39cf0caba81e","30eb51709f0f4c6e8b5fbbcc545bdb56","86e99394e10f44e8a3d9d00ea2202fae","c5a0b94655864e2c979921e318a293d5","5beefa7832634f58b494904bc7acfeb9","f5caf46100ca4f7f829b4dbd3d7aa822","ccce99dc7ab7412684ce63f6bbed924c","85304fec5d624c0dad0a16a09e87c0c7","3a09fc73bf0f4733a0ec6fdc271b1775","16ac9ea7630e495c94e3c27adb9716e8","4f40f1f218884ca9a650f0dbb615cafb","340f1e6c4363425ba69808ecc644f134","48a91d5f880346f0b68301deb30124b8","9cc7f16384f84306b9908c49245d2665","417788178c4949958e7133d7f533056d","e99e1ec5be58419da1b037a14a62fb29","a551d6f1b848455b8edaa9f4b35846c9","8a77649ad3424038ad3d12a883bba12b","266b2984d4574d88924eae338aefa089","73754cdc8b0b415cbffbb874bd440270","bff3912ecb9b4166960e59079264f202","fcce9e52d06541dabacaf393b17690f3","b5211b53d5994dfab9ea8d088bad6735","d65d78aa1b0747448237447dada8518c","73951398bb8b439e9e1c5a7a56473ff4","ef991c408e554d79a934a50a03025b5a","74c35621a4bf42e7bb4220cfd7d2946a","81a41b5eebf543f4b4fd14a12c17725f","73e66eb006da45ff87b3f81b8805d1dc","daa6654744d949488dca3856f4c83068","38416977d0f347c487bd18ace0d73efd","9b7ec0e4ce1347ecb7ec5cf564f2c4f8","03cb975ca36542629278589ade3590d8","3aed2d108a8d4470bbf36168cdd653ab","d492fa6d35284ac6878af2e7b16fce5a","50eecab4b29a4df1ae116a6f97b77af2","e05285feacab4eb1b858f37783754dff","9e30a86bdf784aa49afeecadc60b008d","9337ccacdd2f415e95294df1f742ebd6"]},"executionInfo":{"elapsed":23132,"status":"ok","timestamp":1708276767017,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"},"user_tz":-360},"id":"9z9eXknsUPpV","outputId":"095a216f-548e-470a-b917-c2daeb1d886e","execution":{"iopub.status.busy":"2024-02-18T17:46:57.702444Z","iopub.execute_input":"2024-02-18T17:46:57.702844Z","iopub.status.idle":"2024-02-18T17:46:59.956169Z","shell.execute_reply.started":"2024-02-18T17:46:57.702815Z","shell.execute_reply":"2024-02-18T17:46:59.954724Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\nSome weights of BertModel were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"name: bert.embeddings.word_embeddings.weight is trainable\nname: bert.embeddings.position_embeddings.weight is trainable\nname: bert.embeddings.token_type_embeddings.weight is trainable\nname: bert.embeddings.LayerNorm.weight is trainable\nname: bert.embeddings.LayerNorm.bias is trainable\nname: bert.encoder.layer.0.attention.self.query.weight is trainable\nname: bert.encoder.layer.0.attention.self.query.bias is trainable\nname: bert.encoder.layer.0.attention.self.key.weight is trainable\nname: bert.encoder.layer.0.attention.self.key.bias is trainable\nname: bert.encoder.layer.0.attention.self.value.weight is trainable\nname: bert.encoder.layer.0.attention.self.value.bias is trainable\nname: bert.encoder.layer.0.attention.output.dense.weight is trainable\nname: bert.encoder.layer.0.attention.output.dense.bias is trainable\nname: bert.encoder.layer.0.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.0.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.0.intermediate.dense.weight is trainable\nname: bert.encoder.layer.0.intermediate.dense.bias is trainable\nname: bert.encoder.layer.0.output.dense.weight is trainable\nname: bert.encoder.layer.0.output.dense.bias is trainable\nname: bert.encoder.layer.0.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.0.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.1.attention.self.query.weight is trainable\nname: bert.encoder.layer.1.attention.self.query.bias is trainable\nname: bert.encoder.layer.1.attention.self.key.weight is trainable\nname: bert.encoder.layer.1.attention.self.key.bias is trainable\nname: bert.encoder.layer.1.attention.self.value.weight is trainable\nname: bert.encoder.layer.1.attention.self.value.bias is trainable\nname: bert.encoder.layer.1.attention.output.dense.weight is trainable\nname: bert.encoder.layer.1.attention.output.dense.bias is trainable\nname: bert.encoder.layer.1.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.1.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.1.intermediate.dense.weight is trainable\nname: bert.encoder.layer.1.intermediate.dense.bias is trainable\nname: bert.encoder.layer.1.output.dense.weight is trainable\nname: bert.encoder.layer.1.output.dense.bias is trainable\nname: bert.encoder.layer.1.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.1.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.2.attention.self.query.weight is trainable\nname: bert.encoder.layer.2.attention.self.query.bias is trainable\nname: bert.encoder.layer.2.attention.self.key.weight is trainable\nname: bert.encoder.layer.2.attention.self.key.bias is trainable\nname: bert.encoder.layer.2.attention.self.value.weight is trainable\nname: bert.encoder.layer.2.attention.self.value.bias is trainable\nname: bert.encoder.layer.2.attention.output.dense.weight is trainable\nname: bert.encoder.layer.2.attention.output.dense.bias is trainable\nname: bert.encoder.layer.2.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.2.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.2.intermediate.dense.weight is trainable\nname: bert.encoder.layer.2.intermediate.dense.bias is trainable\nname: bert.encoder.layer.2.output.dense.weight is trainable\nname: bert.encoder.layer.2.output.dense.bias is trainable\nname: bert.encoder.layer.2.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.2.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.3.attention.self.query.weight is trainable\nname: bert.encoder.layer.3.attention.self.query.bias is trainable\nname: bert.encoder.layer.3.attention.self.key.weight is trainable\nname: bert.encoder.layer.3.attention.self.key.bias is trainable\nname: bert.encoder.layer.3.attention.self.value.weight is trainable\nname: bert.encoder.layer.3.attention.self.value.bias is trainable\nname: bert.encoder.layer.3.attention.output.dense.weight is trainable\nname: bert.encoder.layer.3.attention.output.dense.bias is trainable\nname: bert.encoder.layer.3.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.3.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.3.intermediate.dense.weight is trainable\nname: bert.encoder.layer.3.intermediate.dense.bias is trainable\nname: bert.encoder.layer.3.output.dense.weight is trainable\nname: bert.encoder.layer.3.output.dense.bias is trainable\nname: bert.encoder.layer.3.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.3.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.4.attention.self.query.weight is trainable\nname: bert.encoder.layer.4.attention.self.query.bias is trainable\nname: bert.encoder.layer.4.attention.self.key.weight is trainable\nname: bert.encoder.layer.4.attention.self.key.bias is trainable\nname: bert.encoder.layer.4.attention.self.value.weight is trainable\nname: bert.encoder.layer.4.attention.self.value.bias is trainable\nname: bert.encoder.layer.4.attention.output.dense.weight is trainable\nname: bert.encoder.layer.4.attention.output.dense.bias is trainable\nname: bert.encoder.layer.4.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.4.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.4.intermediate.dense.weight is trainable\nname: bert.encoder.layer.4.intermediate.dense.bias is trainable\nname: bert.encoder.layer.4.output.dense.weight is trainable\nname: bert.encoder.layer.4.output.dense.bias is trainable\nname: bert.encoder.layer.4.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.4.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.5.attention.self.query.weight is trainable\nname: bert.encoder.layer.5.attention.self.query.bias is trainable\nname: bert.encoder.layer.5.attention.self.key.weight is trainable\nname: bert.encoder.layer.5.attention.self.key.bias is trainable\nname: bert.encoder.layer.5.attention.self.value.weight is trainable\nname: bert.encoder.layer.5.attention.self.value.bias is trainable\nname: bert.encoder.layer.5.attention.output.dense.weight is trainable\nname: bert.encoder.layer.5.attention.output.dense.bias is trainable\nname: bert.encoder.layer.5.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.5.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.5.intermediate.dense.weight is trainable\nname: bert.encoder.layer.5.intermediate.dense.bias is trainable\nname: bert.encoder.layer.5.output.dense.weight is trainable\nname: bert.encoder.layer.5.output.dense.bias is trainable\nname: bert.encoder.layer.5.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.5.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.6.attention.self.query.weight is trainable\nname: bert.encoder.layer.6.attention.self.query.bias is trainable\nname: bert.encoder.layer.6.attention.self.key.weight is trainable\nname: bert.encoder.layer.6.attention.self.key.bias is trainable\nname: bert.encoder.layer.6.attention.self.value.weight is trainable\nname: bert.encoder.layer.6.attention.self.value.bias is trainable\nname: bert.encoder.layer.6.attention.output.dense.weight is trainable\nname: bert.encoder.layer.6.attention.output.dense.bias is trainable\nname: bert.encoder.layer.6.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.6.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.6.intermediate.dense.weight is trainable\nname: bert.encoder.layer.6.intermediate.dense.bias is trainable\nname: bert.encoder.layer.6.output.dense.weight is trainable\nname: bert.encoder.layer.6.output.dense.bias is trainable\nname: bert.encoder.layer.6.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.6.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.7.attention.self.query.weight is trainable\nname: bert.encoder.layer.7.attention.self.query.bias is trainable\nname: bert.encoder.layer.7.attention.self.key.weight is trainable\nname: bert.encoder.layer.7.attention.self.key.bias is trainable\nname: bert.encoder.layer.7.attention.self.value.weight is trainable\nname: bert.encoder.layer.7.attention.self.value.bias is trainable\nname: bert.encoder.layer.7.attention.output.dense.weight is trainable\nname: bert.encoder.layer.7.attention.output.dense.bias is trainable\nname: bert.encoder.layer.7.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.7.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.7.intermediate.dense.weight is trainable\nname: bert.encoder.layer.7.intermediate.dense.bias is trainable\nname: bert.encoder.layer.7.output.dense.weight is trainable\nname: bert.encoder.layer.7.output.dense.bias is trainable\nname: bert.encoder.layer.7.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.7.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.8.attention.self.query.weight is trainable\nname: bert.encoder.layer.8.attention.self.query.bias is trainable\nname: bert.encoder.layer.8.attention.self.key.weight is trainable\nname: bert.encoder.layer.8.attention.self.key.bias is trainable\nname: bert.encoder.layer.8.attention.self.value.weight is trainable\nname: bert.encoder.layer.8.attention.self.value.bias is trainable\nname: bert.encoder.layer.8.attention.output.dense.weight is trainable\nname: bert.encoder.layer.8.attention.output.dense.bias is trainable\nname: bert.encoder.layer.8.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.8.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.8.intermediate.dense.weight is trainable\nname: bert.encoder.layer.8.intermediate.dense.bias is trainable\nname: bert.encoder.layer.8.output.dense.weight is trainable\nname: bert.encoder.layer.8.output.dense.bias is trainable\nname: bert.encoder.layer.8.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.8.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.9.attention.self.query.weight is trainable\nname: bert.encoder.layer.9.attention.self.query.bias is trainable\nname: bert.encoder.layer.9.attention.self.key.weight is trainable\nname: bert.encoder.layer.9.attention.self.key.bias is trainable\nname: bert.encoder.layer.9.attention.self.value.weight is trainable\nname: bert.encoder.layer.9.attention.self.value.bias is trainable\nname: bert.encoder.layer.9.attention.output.dense.weight is trainable\nname: bert.encoder.layer.9.attention.output.dense.bias is trainable\nname: bert.encoder.layer.9.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.9.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.9.intermediate.dense.weight is trainable\nname: bert.encoder.layer.9.intermediate.dense.bias is trainable\nname: bert.encoder.layer.9.output.dense.weight is trainable\nname: bert.encoder.layer.9.output.dense.bias is trainable\nname: bert.encoder.layer.9.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.9.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.10.attention.self.query.weight is trainable\nname: bert.encoder.layer.10.attention.self.query.bias is trainable\nname: bert.encoder.layer.10.attention.self.key.weight is trainable\nname: bert.encoder.layer.10.attention.self.key.bias is trainable\nname: bert.encoder.layer.10.attention.self.value.weight is trainable\nname: bert.encoder.layer.10.attention.self.value.bias is trainable\nname: bert.encoder.layer.10.attention.output.dense.weight is trainable\nname: bert.encoder.layer.10.attention.output.dense.bias is trainable\nname: bert.encoder.layer.10.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.10.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.10.intermediate.dense.weight is trainable\nname: bert.encoder.layer.10.intermediate.dense.bias is trainable\nname: bert.encoder.layer.10.output.dense.weight is trainable\nname: bert.encoder.layer.10.output.dense.bias is trainable\nname: bert.encoder.layer.10.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.10.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.11.attention.self.query.weight is trainable\nname: bert.encoder.layer.11.attention.self.query.bias is trainable\nname: bert.encoder.layer.11.attention.self.key.weight is trainable\nname: bert.encoder.layer.11.attention.self.key.bias is trainable\nname: bert.encoder.layer.11.attention.self.value.weight is trainable\nname: bert.encoder.layer.11.attention.self.value.bias is trainable\nname: bert.encoder.layer.11.attention.output.dense.weight is trainable\nname: bert.encoder.layer.11.attention.output.dense.bias is trainable\nname: bert.encoder.layer.11.attention.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.11.attention.output.LayerNorm.bias is trainable\nname: bert.encoder.layer.11.intermediate.dense.weight is trainable\nname: bert.encoder.layer.11.intermediate.dense.bias is trainable\nname: bert.encoder.layer.11.output.dense.weight is trainable\nname: bert.encoder.layer.11.output.dense.bias is trainable\nname: bert.encoder.layer.11.output.LayerNorm.weight is trainable\nname: bert.encoder.layer.11.output.LayerNorm.bias is trainable\nname: bert.pooler.dense.weight is trainable\nname: bert.pooler.dense.bias is trainable\nname: out.weight is trainable\nname: out.bias is trainable\n","output_type":"stream"}]},{"cell_type":"code","source":"#testing if the input of model works before starting training\ns = \"আমি বাংলায় গান গাই। [SEP]\"\n\n# debugging dataloader\n# i = 0\n# for batch in train_dataloader:\n#   text, labels = batch\n#   for j in range(len(text)):\n#     print(i+1)\n#     i+=1\n\n# s=headlineContentSeparator\n# print(s)\nt = tokenizer.encode_plus(s, return_tensors=\"pt\").to(device)\nprint(t)\nout = model(**t)\nprint(out)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3038,"status":"ok","timestamp":1708276778748,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"},"user_tz":-360},"id":"OmRT5yjsvdDK","outputId":"fe710620-0d5f-4890-dbef-230b5925aca6","execution":{"iopub.status.busy":"2024-02-18T17:47:08.836184Z","iopub.execute_input":"2024-02-18T17:47:08.836902Z","iopub.status.idle":"2024-02-18T17:47:09.066225Z","shell.execute_reply.started":"2024-02-18T17:47:08.836862Z","shell.execute_reply":"2024-02-18T17:47:09.065083Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"{'input_ids': tensor([[   2,  857,    1, 1755, 3893,  205,    3,    3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\ntensor([[-0.2408, -0.2054,  0.0465,  0.1316]], grad_fn=<AddmmBackward0>)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(df_train.iloc[94]['Headline'],df_train.iloc[94]['Content'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":363,"status":"ok","timestamp":1708276790979,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"},"user_tz":-360},"id":"fUJOHWMgm3fw","outputId":"fc9976e3-8748-4545-931c-6c69ad71a33c","execution":{"iopub.status.busy":"2024-02-18T18:18:22.467702Z","iopub.execute_input":"2024-02-18T18:18:22.468158Z","iopub.status.idle":"2024-02-18T18:18:22.475916Z","shell.execute_reply.started":"2024-02-18T18:18:22.468126Z","shell.execute_reply":"2024-02-18T18:18:22.474676Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"বর্ণাঢ্য আয়োজনে উন্নয়ন মেলার শুরু, প্রথম দিনেই ভিড় রাজশাহী: রাজশাহীতে বর্ণাঢ্য আয়োজনে শুরু হয়েছে চতুর্থ জাতীয় উন্নয়ন মেলা-২০১৮। প্রথম দিনেই মেলায় উপচেপড়া ভিড় লক্ষ্য করা গেছে। বৃহস্পতিবার (০৪ অক্টোবর) দুপুরে প্রধানমন্ত্রী শেখ হাসিনা ভিডিও কনফান্সের মাধ্যমে দেশব্যাপী এ মেলার উদ্বোধন করেন। পরে রাজশাহী সিটি করপোরেশনের (রাসিক) মেয়র এএইচএম খায়রুজ্জামান লিটন প্রধান অতিথি হিসেবে উপস্থিত থেকে বেলুন ও পায়রা উড়িয়ে স্থানীয়ভাবে মেলার উদ্বোধন করেন। এসময় রাজশাহী জেলা প্রশাসক এসএম আব্দুল কাদেরের সভাপতিত্বে অনুষ্ঠানে আরও উপস্থিত ছিলেন-ভূমি সংরক্ষণ বিভাগের অতিরিক্ত সচিব সালমা আকতার জাহান, প্রধানমন্ত্রীর কার্যালয়ের এনজিও ব্যুরোর মহাপরিচালক কেএম আব্দুস সালাম, বিভাগীয় কমিশনার নূর-উর রহমান, মহানগর আওয়ামী লীগের সিনিয়র সহ-সভাপতি শাহীন আকতার রেনী, পুলিশের রাজশাহী রেঞ্জের ডিআইজি খুরশিদ হোসেন, মহানগর পুলিশ কমিশনার একেএম হাফিজ আক্তার, সংরক্ষিত আসনের সংসদ সদস্য আকতার জাহান, সাবেক প্রতিমন্ত্রী অধ্যাপিকা জিন্নাতুন নেসা তালুকদার, মহানগর আওয়ামী লীগের সাধারণ সম্পাদক ডাবলু সরকার, রাজশাহী কলেজ অধ্যক্ষ অধ্যাপক মুহা. হবিবুর রহমান, রাজশাহী জেলা পরিষদের প্রশাসক মোহাম্মদ আলী সরকার প্রমুখ। সভায় মেয়র বলেন, ‘প্রধানন্ত্রী শেখ হাসিনার নেতৃত্বে সর্বদিক দিয়ে এগিয়ে যাচ্ছে বাংলাদেশ। তার প্রমাণ আজকে আমরা আবারও পেলাম এ সরকারের সুবিধাভোগী বিভিন্ন শ্রেণি-পেশার মানুষের মুখ থেকে। বাংলাদেশ থেমে নেই। উন্নয়নের মহাসড়কে বাংলাদেশ উঠে গেছে, এখন দ্রুত বেগে এগিয়ে যাচ্ছে। এটি আমাদের অহংকার, এটি আমাদের গর্ব।’ মেয়র লিটন বলেন, বাংলাদেশের প্রতি টার্গেট করে পুরো ভারতবর্ষ তাকিয়ে আছে। তারা অবাক হয়ে তাকিয়ে দেখছে বাংলাদেশ কীভাবে এগিয়ে যাচ্ছে। খায়রুজ্জামান লিটন বলেন, প্রধানমন্ত্রী শেখ হাসিনা দেশের সার্বিক উন্নয়ন করছেন। তার ধারাবাহিকতায় রাজশহীতেও উন্নয়ন হচ্ছে। আগামী কয়েক মাসের মধ্যে রাজশাহীর পদ্মা নদীতে ক্যাপিটাল ড্রেজিং করা হবে। মহানগরীর তলদেশে ভরাট হয়ে যাওয়া মাটি শহরের পাশে ফেলে ভরাট করা হবে। আমরা প্রায় ১০ থেকে ১৫ বর্গকিলোমিটার জায়গা নতুন করে উদ্ধার করতে পারবো। সেখানে আমরা অনেক স্থাপনা করতে পারবো। বিনোদন কেন্দ্র হবে, ইকো পার্ক হবে। এর আগে সকাল সাড়ে নয়টায় মহানগরীর কুমারপাড়া মোড় থেকে উন্নয়ন মেলা উপলক্ষে এক বর্ণাঢ্য শোভাযাত্রা বের করা হয়।শোভাযাত্রাটি মহানগরীর সাহেববাজারসহ বিভিন্ন সড়ক ঘুরে রাজশাহী কলেজ মাঠে গিয়ে শেষ হয়। রাজশাহীর ঐতিহ্যবাহী ঘোড়ার টমটম শোভাযাত্রার সৌন্দর্য্য বর্ধণ করে। শোভাযাত্রায় সরকারের বিভিন্ন দফতরের কর্মকর্তা, স্কুল-কলেজের শিক্ষক-শিক্ষার্থীসহ বিভিন্ন শ্রেণি-পেশার কয়েক হাজার মানুষ অংশ নেন। এদিকে, প্রথম দিনেই মেলায় উপচেপড়া ভিড় লক্ষ্য করা গেছে। এবারের মেলা সরকারি-বেসরকারি ১৮০টির বেশি প্রতিষ্ঠানে বিভিন্ন উন্নয়ন বিষয়ক কার্যক্রম শোভা পাচ্ছে। এছাড়া মেলায় শিক্ষার্থীদের নিয়ে সরকারের সফলতা বিষয়ক রিয়েলিটি শো প্রদর্শন এবং মুক্তিযুদ্ধ ও সরকারের সফলতাকে উপজীব্য করে সাংস্কৃতিক অনুষ্ঠান অনুষ্ঠিত হবে। এ ব্যাপারে যথেষ্ট নিরাপত্তার ব্যবস্থা নেওয়া হয়েছে। প্রতিদিন সকাল নয়টা থেকে রাত আটটা পর্যন্ত সবার জন্য মেলা উন্মুক্ত থাকবে। রাজশাহী কলেজ মাঠে আগামী ৬ অক্টোবর পর্যন্ত এ উন্নয়ন মেলা চলবে। মেলায় সরকারের বিভিন্ন দফতরের স্টলগুলোতে উন্নয়নের চিত্র তুলে ধরা হচ্ছে। বাংলাদেশ সময়: ১৭২০ ঘণ্টা, অক্টোবর ০৪, ২০১৮ এসএস/ওএইচ/\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\noptimizer = AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=adam_opt_lr)\ncriterion = nn.CrossEntropyLoss()\nscheduler = StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)","metadata":{"id":"ZaJ8Ro_CxcPQ","executionInfo":{"status":"ok","timestamp":1708276821945,"user_tz":-360,"elapsed":353,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T18:18:26.025327Z","iopub.execute_input":"2024-02-18T18:18:26.025768Z","iopub.status.idle":"2024-02-18T18:18:26.034526Z","shell.execute_reply.started":"2024-02-18T18:18:26.025733Z","shell.execute_reply":"2024-02-18T18:18:26.033109Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def train(model, dataloader, optimizer, criterion, config):\n    model.train()  # prep model for training\n    train_loss = 0\n    for batch in tqdm(dataloader):\n        text, labels = batch\n\n        model.zero_grad()\n\n        inputs = tokenizer.batch_encode_plus(\n            text, **config\n        )\n        input_ids = inputs['input_ids'].to(device)\n        token_type_ids = inputs['token_type_ids'].to(device)\n        attention_mask = inputs['attention_mask'].to(device)\n        #labels = labels.to(device)\n        labels = labels.to(device, dtype=torch.long)  # Convert labels to torch.long\n\n        # move things to model\n        logs = model( input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n\n        loss = criterion(logs, labels)\n        #print(\"successfully calculated criterion in train!\")\n        train_loss += loss.item() * input_ids.size(0)\n        loss.backward()\n\n        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n\n    return train_loss","metadata":{"id":"Q-YKSmNf1HrB","executionInfo":{"status":"ok","timestamp":1708276826528,"user_tz":-360,"elapsed":379,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T18:18:29.020617Z","iopub.execute_input":"2024-02-18T18:18:29.021150Z","iopub.status.idle":"2024-02-18T18:18:29.036655Z","shell.execute_reply.started":"2024-02-18T18:18:29.021109Z","shell.execute_reply":"2024-02-18T18:18:29.035626Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion, config):\n    total = 0\n    correct = 0\n    valid_loss = 0.0\n    label_0_TP = 0\n    label_0_TN = 0\n    label_0_FP = 0\n    label_0_FN = 0\n\n    label_1_TP = 0\n    label_1_TN = 0\n    label_1_FP = 0\n    label_1_FN = 0\n\n    label_2_TP = 0\n    label_2_TN = 0\n    label_2_FP = 0\n    label_2_FN = 0\n\n    model.eval()  # prep model for evaluation\n    for batch in dataloader:\n        text, labels = batch\n        inputs = tokenizer.batch_encode_plus(\n            text, **config\n        )\n        input_ids = inputs['input_ids'].to(device)\n        token_type_ids = inputs['token_type_ids'].to(device)\n        attention_mask = inputs['attention_mask'].to(device)\n        labels = labels.to(device, dtype=torch.long)\n\n        # move things to model\n        output = model(input_ids=input_ids, attention_mask=attention_mask,token_type_ids=token_type_ids)\n\n        loss_p = criterion(output, labels)\n        # update running validation loss\n        valid_loss += loss_p.item() * input_ids.size(0)\n        # calculate accuracy\n        proba = torch.exp(output)\n        top_p, top_class = proba.topk(1, dim=1)\n        equals = top_class == labels.view(*top_class.shape)\n        # accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n\n        _, predicted = torch.max(output.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        #print(f'predicted: {predicted} labels: {labels}')\n        label_0_TP += ((predicted == 0) & (labels == 0)).sum().item()\n        label_0_TN += ((predicted != 0) & (labels != 0)).sum().item()\n        label_0_FP += ((predicted == 0) & (labels != 0)).sum().item()\n        label_0_FN += ((predicted != 0) & (labels == 0)).sum().item()\n\n        label_1_TP += ((predicted == 1) & (labels == 1)).sum().item()\n        label_1_TN += ((predicted != 1) & (labels != 1)).sum().item()\n        label_1_FP += ((predicted == 1) & (labels != 1)).sum().item()\n        label_1_FN += ((predicted != 1) & (labels == 1)).sum().item()\n\n        label_2_TP += ((predicted == 2) & (labels == 2)).sum().item()\n        label_2_TN += ((predicted != 2) & (labels != 2)).sum().item()\n        label_2_FP += ((predicted == 2) & (labels != 2)).sum().item()\n        label_2_FN += ((predicted != 2) & (labels == 2)).sum().item()\n\n    return total, correct, valid_loss, label_0_TP, label_0_TN, label_0_FP, label_0_FN, label_1_TP, label_1_TN, label_1_FP, label_1_FN, label_2_TP, label_2_TN, label_2_FP, label_2_FN\n","metadata":{"id":"WULrKYWT1jyv","executionInfo":{"status":"ok","timestamp":1708276830553,"user_tz":-360,"elapsed":403,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T18:18:32.646972Z","iopub.execute_input":"2024-02-18T18:18:32.647394Z","iopub.status.idle":"2024-02-18T18:18:32.668468Z","shell.execute_reply.started":"2024-02-18T18:18:32.647362Z","shell.execute_reply":"2024-02-18T18:18:32.666191Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"\ntokenizer_config = {\n    \"max_length\": max_number_input_tokens,\n    \"padding\": \"max_length\",\n    \"return_tensors\": \"pt\",\n    \"truncation\": True,\n    \"add_special_tokens\": True,\n     \"truncation_strategy\":\"longest_first\"\n}","metadata":{"id":"Jfz6yeuc1pUZ","executionInfo":{"status":"ok","timestamp":1708276834825,"user_tz":-360,"elapsed":336,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T18:18:38.283607Z","iopub.execute_input":"2024-02-18T18:18:38.284037Z","iopub.status.idle":"2024-02-18T18:18:38.290386Z","shell.execute_reply.started":"2024-02-18T18:18:38.284004Z","shell.execute_reply":"2024-02-18T18:18:38.289059Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_loss_data, valid_loss_data = [], []\nvalid_loss_min = np.Inf\nsince = time.time()\nbest_loss = np.inf\nbest_acc=0\nsml = 1e-10\nbest_f1=0.0\n\nfor epoch in range(epochs):\n    print(\"Epoch: {}/{}\".format(epoch + 1, epochs))\n    # monitor training loss\n    train_loss = 0.0\n    valid_loss = 0.0\n    total = 0\n    correct = 0\n    label_0_TP = 0\n    label_0_TN = 0\n    label_0_FP = 0\n    label_0_FN = 0\n\n    label_1_TP = 0\n    label_1_TN = 0\n    label_1_FP = 0\n    label_1_FN = 0\n\n    label_2_TP = 0\n    label_2_TN = 0\n    label_2_FP = 0\n    label_2_FN = 0\n\n\n    e_since = time.time()\n\n    # Train Model\n    train_loss += train(model, train_dataloader, optimizer, criterion, tokenizer_config)\n    # Now Evaluate\n    out = evaluate(model, val_dataloader, criterion, tokenizer_config)\n    total += out[0]\n    correct += out[1]\n    valid_loss += out[2]\n    label_0_TP += out[3]\n    label_0_TN += out[4]\n    label_0_FP += out[5]\n    label_0_FN += out[6]\n\n    label_1_TP += out[7]\n    label_1_TN += out[8]\n    label_1_FP += out[9]\n    label_1_FN += out[10]\n\n    # label_2_TP += out[11]\n    # label_2_TN += out[12]\n    # label_2_FP += out[13]\n    # label_2_FN += out[14]\n\n    # Calculate precision, recall, and F1-score for each class\n    label_0_precision = label_0_TP / (label_0_TP + label_0_FP+sml)\n    label_0_recall = label_0_TP / (label_0_TP + label_0_FN+sml)\n    label_0_f1_score = 2 * (label_0_precision * label_0_recall) / (label_0_precision + label_0_recall+sml)\n\n    label_1_precision = label_1_TP / (label_1_TP + label_1_FP+sml)\n    label_1_recall = label_1_TP / (label_1_TP + label_1_FN+sml)\n    label_1_f1_score = 2 * (label_1_precision * label_1_recall) / (label_1_precision + label_1_recall+sml)\n\n    label_2_precision = label_2_TP / (label_2_TP + label_2_FP+sml)\n    label_2_recall = label_2_TP / (label_2_TP + label_2_FN+sml)\n    label_2_f1_score = 2 * (label_2_precision * label_2_recall) / (label_2_precision + label_2_recall+sml)\n\n    # Calculate combined F1-score\n    combined_f1_score = (label_0_f1_score + label_1_f1_score) / 2\n\n    # Calculate micro TP, TN, FP, FN values\n    micro_TP = label_0_TP + label_1_TP\n    micro_TN = label_0_TN + label_1_TN\n    micro_FP = label_0_FP + label_1_FP\n    micro_FN = label_0_FN + label_1_FN\n\n    # Calculate micro precision, recall, and F1 score\n    micro_precision = micro_TP / (micro_TP + micro_FP)\n    micro_recall = micro_TP / (micro_TP + micro_FN)\n    micro_f1 = 2 * (micro_precision * micro_recall) / (micro_precision + micro_recall)\n\n    scheduler.step()\n\n    # print training/validation statistics\n    # calculate average loss over an epoch\n    train_loss = train_loss / len(train_dataloader.dataset)\n    valid_loss = valid_loss / len(val_dataloader.dataset)\n\n    val_acc=correct / total * 100\n\n    # calculate train loss and running loss\n    train_loss_data.append(train_loss * 100)\n    valid_loss_data.append(valid_loss * 100)\n\n    if combined_f1_score > best_f1:\n        best_f1 = combined_f1_score\n        torch.save(model.state_dict(), ModelPath)\n        print(f'saved on epoch: {epoch+1}')\n\n    print(\"\\tTrain loss:{:.6f}..\".format(train_loss),\n          \"\\tValid Loss:{:.6f}..\".format(valid_loss),\n          \"\\tVal Accuracy: {:.4f}\".format(correct / total * 100))\n    print(\"\\tLabel 0 Precision: {:.4f}\\tLabel 0 Recall: {:.4f}\\tLabel 0 F1-score: {:.4f}\\n\"\n      \"\\tLabel 1 Precision: {:.4f}\\tLabel 1 Recall: {:.4f}\\tLabel 1 F1-score: {:.4f}\\n\"\n      \"\\tLabel 2 Precision: {:.4f}\\tLabel 2 Recall: {:.4f}\\tLabel 2 F1-score: {:.4f}\\n\"\n      \"\\tCombined F1-score: {:.4f}\".format(label_0_precision, label_0_recall, label_0_f1_score,\n                                            label_1_precision, label_1_recall, label_1_f1_score,\n                                            label_2_precision, label_2_recall, label_2_f1_score,\n                                            combined_f1_score))\n    print(f'micro precision: {micro_precision}, Micro recall: {micro_recall}, micro f1: {micro_f1}')\n\ntime_elapsed = time.time() - since\nprint('Training completed in {:.0f}m {:.0f}s'.format(\n    time_elapsed // 60, time_elapsed % 60))","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":371,"referenced_widgets":["2e2617f931c444f58b0ccb9649527680","bc4d530f0b3d438a9ad64955a10a7011","ad38e2b0d53d41a8a42c6aa5ce03ae70","47dfa97370e74a1bb68847fe380f4b47","d8026ac7d54c4d078b0963f296f3198b","3cd0becb06da485b942208514af75436","be22b4adc4d145b882eecd0cb35ba531","dc6657b5da8b45e3b183fb209f2544c7","72281ee75f3c444f9b102b3eabaa3050","9aa909bfdcd142edb4095173209d6656","be3923c9d6fc4177b75465a301b897d1"]},"id":"petGI7zd4LAm","outputId":"2709e52e-8351-46bd-b50d-64a70dab7cab","executionInfo":{"status":"error","timestamp":1708277208783,"user_tz":-360,"elapsed":369986,"user":{"displayName":"Hrithik Majumdar","userId":"11846052037123999694"}},"execution":{"iopub.status.busy":"2024-02-18T18:18:41.929699Z","iopub.execute_input":"2024-02-18T18:18:41.930100Z","iopub.status.idle":"2024-02-18T18:22:15.786584Z","shell.execute_reply.started":"2024-02-18T18:18:41.930072Z","shell.execute_reply":"2024-02-18T18:22:15.784938Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch: 1/8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5389 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487b36aeb658498c90f217949f4e760f"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[19], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m e_since \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train Model\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Now Evaluate\u001b[39;00m\n\u001b[1;32m     37\u001b[0m out \u001b[38;5;241m=\u001b[39m evaluate(model, val_dataloader, criterion, tokenizer_config)\n","Cell \u001b[0;32mIn[16], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, criterion, config)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# prep model for training\u001b[39;00m\n\u001b[1;32m      3\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader):\n\u001b[1;32m      5\u001b[0m     text, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[1;32m      7\u001b[0m     model\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[7], line 20\u001b[0m, in \u001b[0;36mNewsDatasets.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     18\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(value[\"Headline\"],value['Content']) #debugging dataloader\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mHeadline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mheadlineContentSeparator\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mContent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m , value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"float\") to str"],"ename":"TypeError","evalue":"can only concatenate str (not \"float\") to str","output_type":"error"}]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"id":"muKYec9IECUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.save(model.state_dict(), DirPath+bert_model_name+\"_lasttwopoolerf_contest_val_from_finalhs_midnonfrozen_acc1_sub_finaluntested.pth\")","metadata":{"id":"gcnJ4S_u65BO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\nplt.plot(train_loss_data, label=\"Training loss\")\nplt.plot(valid_loss_data, label=\"validation loss\")\nplt.legend(frameon=False)","metadata":{"id":"sYYhjA944Qgi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing on test dataset","metadata":{"id":"lfWfx3Zi4COD"}},{"cell_type":"code","source":"model.load_state_dict(torch.load(ModelPath))","metadata":{"colab":{"background_save":true},"id":"-d8iU2p64rrh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = []\nall_labels = []\n\n\ndf_test = pd.read_csv(TestPath)\ntest_data = NewsDatasets(df_test)\ntest_dataloader = DataLoader(test_data, batch_size=batch_size_training, shuffle=False)\n\nfor batch in test_dataloader:\n    text, labels = batch\n    inputs = tokenizer.batch_encode_plus(\n        text, **tokenizer_config\n    )\n    input_ids = inputs['input_ids'].to(device)\n    token_type_ids = inputs['token_type_ids'].to(device)\n    attention_mask = inputs['attention_mask'].to(device)\n    labels = labels.to(device)\n\n    # move things to model\n    output = model(token_type_ids=token_type_ids, input_ids=input_ids, attention_mask=attention_mask)\n    preds = output.detach().cpu().numpy()\n    preds = np.argmax(preds, axis = 1)\n    all_preds.extend(preds)\n    all_labels.extend(labels.cpu().numpy())\n\n# df_test['real_HS'] = all_labels\n# df_test['predicted_HS'] = all_preds\n# df_test.to_csv(DirPath+'nc/'+'test_HS_pred.csv')","metadata":{"id":"VD8JGmErGJEw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(all_preds))","metadata":{"id":"WjkUCAtGe5mm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\n\n# preds = np.argmax(preds, axis = 1)\nprint(classification_report(all_labels, all_preds, digits=4))","metadata":{"id":"m7UdyABYGRdb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"KDrNVhFXor-F"},"execution_count":null,"outputs":[]}]}